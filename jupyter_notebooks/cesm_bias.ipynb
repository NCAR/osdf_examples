{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc65f494-4fbe-4af0-85ca-e3a424b56454",
   "metadata": {},
   "source": [
    "# Bias-correct CESM2 LENS temperature data using ERA5 reanalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ca3999-b076-4dc9-8172-6d14ba082229",
   "metadata": {},
   "source": [
    "### Input Data Access\n",
    "- This notebook illustrates how to bias-correct daily temperature data from CESM2 Large Ensemble Dataset (https://www.cesm.ucar.edu/community-projects/lens2) hosted on AWS.\n",
    "- This data is open access (https://aws.amazon.com/marketplace/pp/prodview-xilranwbl2ep2#resources)\n",
    "- We will access the data using OSDF's AWS open data origin.\n",
    "- The OSDF zarr paths are obtained from an intake catalog which lives on NCAR's Research Data Archive and is publicly accessible via https.\n",
    "- We will use NCAR's origin to access the publicly available ERA5 reanalysis.\n",
    "- In summary, this notebook illustrates how we can access data from two different OSDF origins using PelicanFS and perform an interesting computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75379e41-148d-4236-be98-9e25e9e47cf0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Computational resources and Output data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75c0b21-370e-46ff-917a-18aee9f096bd",
   "metadata": {},
   "source": [
    "- If you don't have access to NCAR's HPC system, please select the appropriate cluster\n",
    "- All the intermediate results and the final result will be written to NCAR's GLADE storage system, which doesn't have public write access.\n",
    "- You are welcome to modify this to suit your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9a4b04-ef0a-49bf-b2f2-17c5ff869737",
   "metadata": {},
   "source": [
    "#### Import package, define parameters and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20444ba4-275a-45a7-bda5-c22b5cb5cee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display output of plots directly in Notebook\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import intake\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "# import s3fs\n",
    "import seaborn as sns\n",
    "import re\n",
    "# import nest_asyncio\n",
    "# nest_asyncio.apply()\n",
    "import xesmf as xe\n",
    "import matplotlib.pyplot as plt\n",
    "# import cartopy as cart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63e53607-bf0a-41a4-9f72-5769197e4570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec.implementations.http as fshttp\n",
    "from pelicanfs.core import PelicanFileSystem, PelicanMap, OSDFFileSystem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9928a424-cf23-4a2f-bf16-afe7137d296f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask \n",
    "from dask_jobqueue import PBSCluster\n",
    "from dask.distributed import Client\n",
    "from dask.distributed import performance_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06e969a1-f9fc-467c-9732-fd2f9bb44361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dask.config.set at 0x14bd59972570>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This overwrites the default scheduler with a single-threaded scheduler\n",
    "dask.config.set(scheduler='synchronous')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "961a7413-7c37-42a3-9891-14935fb12bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_year0  = '1991'\n",
    "init_year1  = '2020'\n",
    "final_year0 = '2071'\n",
    "final_year1 = '2100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef9b6c48-22f6-476b-8261-7427e6186b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_daily(ds):\n",
    "    year = ds.time.dt.year\n",
    "    day = ds.time.dt.dayofyear\n",
    "\n",
    "    # assign new coords\n",
    "    ds = ds.assign_coords(year=(\"time\", year.data), day=(\"time\", day.data))\n",
    "\n",
    "    # reshape the array to (..., \"day\", \"year\")\n",
    "    return ds.set_index(time=(\"year\", \"day\")).unstack(\"time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9355d14-86f5-4236-a986-44af18453483",
   "metadata": {},
   "outputs": [],
   "source": [
    "rda_scratch = '/gpfs/csfs1/collections/rda/scratch/harshah'\n",
    "zarr_path   = rda_scratch + \"/tas_zarr/\"\n",
    "mean_path   = zarr_path + \"/means/\"\n",
    "stdev_path  = zarr_path + \"/stdevs/\"\n",
    "#\n",
    "rda_url        =  'https://data.rda.ucar.edu/'\n",
    "intake_url     = rda_url + 'harshah/intake_catalogs/cesm2-lens-osdf/aws-cesm2-le.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67acfb7e-79c0-4484-b0f8-2097846d7bb1",
   "metadata": {},
   "source": [
    "### Create a Dask cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c1a9cf-887d-424d-b863-2f30a48e4211",
   "metadata": {},
   "source": [
    "#### Dask Introduction\n",
    "\n",
    "Dask is a solution that enables the scaling of Python libraries. It mimics popular scientific libraries such as numpy, pandas, and xarray that enables an easier path to parallel processing without having to refactor code.\n",
    "\n",
    "There are 3 components to parallel processing with Dask: the client, the scheduler, and the workers.\n",
    "\n",
    "The Client is best envisioned as the application that sends information to the Dask cluster. In Python applications this is handled when the client is defined with client = Client(CLUSTER_TYPE). A Dask cluster comprises of a single scheduler that manages the execution of tasks on workers. The CLUSTER_TYPE can be defined in a number of different ways.\n",
    "\n",
    "- There is LocalCluster, a cluster running on the same hardware as the application and sharing the available resources, directly in Python with dask.distributed.\n",
    "\n",
    "- In certain JupyterHubs Dask Gateway may be available and a dedicated dask cluster with its own resources can be created dynamically with dask.gateway.\n",
    "\n",
    "- On HPC systems dask_jobqueue is used to connect to the HPC Slurm, PBS or HTCondor job schedulers to provision resources.\n",
    "\n",
    "The dask.distributed client python module can also be used to connect to existing clusters. A Dask Scheduler and Workers can be deployed in containers, or on Kubernetes, without using a Python function to create a dask cluster. The dask.distributed Client is configured to connect to the scheduler either by container name, or by the Kubernetes service name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d84b6a-cb23-42c4-be4f-d0c74eac2814",
   "metadata": {},
   "source": [
    "#### Select the Dask cluster type\n",
    "The default will be LocalCluster as that can run on any system.\n",
    "\n",
    "If running on a HPC computer with a PBS Scheduler, set to True. Otherwise, set to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcac81b8-5fdd-4e5d-b4b7-39796850545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_PBS_SCHEDULER = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52991f0b-f035-46fe-9638-5a7011f2feb6",
   "metadata": {},
   "source": [
    "If running on Jupyter server with Dask Gateway configured, set to True. Otherwise, set to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfa6ea30-bde0-423d-b0e7-0a66c16b450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_DASK_GATEWAY = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd16b1e-05ff-4d3c-a461-2aeb15997fa9",
   "metadata": {},
   "source": [
    "#### Python function for a PBS cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64d70f4e-ea6e-42aa-9430-0630d3566ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PBS cluster object\n",
    "def get_pbs_cluster():\n",
    "    \"\"\" Create cluster through dask_jobqueue.   \n",
    "    \"\"\"\n",
    "    from dask_jobqueue import PBSCluster\n",
    "    cluster = PBSCluster(\n",
    "        job_name = 'dask-osdf-24',\n",
    "        cores = 1,\n",
    "        memory = '4GiB',\n",
    "        processes = 1,\n",
    "        local_directory = rda_scratch + '/dask/spill',\n",
    "        log_directory = rda_scratch + '/dask/logs/',\n",
    "        resource_spec = 'select=1:ncpus=1:mem=4GB',\n",
    "        queue = 'casper',\n",
    "        walltime = '3:00:00',\n",
    "        #interface = 'ib0'\n",
    "        interface = 'ext'\n",
    "    )\n",
    "    return cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dfec14-81f7-4918-9f2a-f18493d961f8",
   "metadata": {},
   "source": [
    "#### Python function for a Gateway Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9da16d2f-4fdf-413e-89bf-e4a7e077d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gateway_cluster():\n",
    "    \"\"\" Create cluster through dask_gateway\n",
    "    \"\"\"\n",
    "    from dask_gateway import Gateway\n",
    "\n",
    "    gateway = Gateway()\n",
    "    cluster = gateway.new_cluster()\n",
    "    cluster.adapt(minimum=2, maximum=4)\n",
    "    return cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731d0188-d11c-4776-b7b2-cc51ed7bfef6",
   "metadata": {},
   "source": [
    "#### Python function for a Local Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d95ce7e7-23ec-452d-9e4c-77b63b4b3dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_local_cluster():\n",
    "    \"\"\" Create cluster using the Jupyter server's resources\n",
    "    \"\"\"\n",
    "    from distributed import LocalCluster, performance_report\n",
    "    cluster = LocalCluster()    \n",
    "\n",
    "    cluster.scale(4)\n",
    "    return cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd47ae54-0432-48f7-801c-0843d49b1c15",
   "metadata": {},
   "source": [
    "#### Python logic to select the Dask Cluster type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac8a3d1-6b9d-465d-864e-2ade389351ee",
   "metadata": {},
   "source": [
    "This uses True/False boolean logic based on the variables set in the previous cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3b72fef-ff00-4bd3-97de-4cf93e91e15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain dask cluster in one of three ways\n",
    "\n",
    "if USE_PBS_SCHEDULER:\n",
    "    cluster = get_pbs_cluster()\n",
    "elif USE_DASK_GATEWAY:\n",
    "    cluster = get_gateway_cluster()\n",
    "else:\n",
    "    cluster = get_local_cluster()\n",
    "\n",
    "# Connect to cluster\n",
    "from distributed import Client\n",
    "client = Client(cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1ab50dc-0496-455e-8b02-acf4ef314b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">PBSCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">3d386446</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"https://jupyterhub.hpc.ucar.edu/stable/user/harshah/proxy/44475/status\" target=\"_blank\">https://jupyterhub.hpc.ucar.edu/stable/user/harshah/proxy/44475/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 0\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 0\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 0 B\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-c2c405db-6a1e-4b37-a8ce-fdb90066d97c</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://128.117.208.94:43187\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"https://jupyterhub.hpc.ucar.edu/stable/user/harshah/proxy/44475/status\" target=\"_blank\">https://jupyterhub.hpc.ucar.edu/stable/user/harshah/proxy/44475/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "PBSCluster(3d386446, 'tcp://128.117.208.94:43187', workers=0, threads=0, memory=0 B)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scale the cluster and display cluster dashboard URL\n",
    "cluster.scale(4)\n",
    "\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e971bb08-6952-4e5a-8c34-5b03fe189562",
   "metadata": {},
   "source": [
    "## Load CESM LENS2 temperature data from AWS using an intake catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be45a360-624a-403b-be3f-6879ec0a5c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong>aws-cesm2-le catalog with 40 dataset(s) from 322 asset(s)</strong>:</p> <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_name</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forcing_variant</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequency</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vertical_levels</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial_domain</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>units</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_time</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_time</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>path</th>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>derived_variable</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cesm_cat = intake.open_esm_datastore(intake_url)\n",
    "cesm_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2dc1598-96bc-491a-8bae-80a90b8dbd3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong>aws-cesm2-le catalog with 4 dataset(s) from 4 asset(s)</strong>:</p> <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>long_name</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forcing_variant</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frequency</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vertical_levels</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial_domain</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>units</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_time</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_time</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>path</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>derived_variable</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cesm_temp = cesm_cat.search(variable ='TREFHTMX', frequency ='daily')\n",
    "cesm_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a192979f-0901-4a6d-8399-f03c81023e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['osdf:///aws-opendata/us-west-2/ncar-cesm2-lens/atm/daily/cesm2LE-historical-cmip6-TREFHTMX.zarr',\n",
       "       'osdf:///aws-opendata/us-west-2/ncar-cesm2-lens/atm/daily/cesm2LE-historical-smbb-TREFHTMX.zarr',\n",
       "       'osdf:///aws-opendata/us-west-2/ncar-cesm2-lens/atm/daily/cesm2LE-ssp370-cmip6-TREFHTMX.zarr',\n",
       "       'osdf:///aws-opendata/us-west-2/ncar-cesm2-lens/atm/daily/cesm2LE-ssp370-smbb-TREFHTMX.zarr'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cesm_temp.df['path'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc63c711-865e-4f21-86dc-03947dac7a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'component.experiment.frequency.forcing_variant'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='2' class='' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.00% [2/4 00:15&lt;00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ESMDataSourceError",
     "evalue": "Failed to load dataset with key='atm.historical.daily.smbb'\n                 You can use `cat['atm.historical.daily.smbb'].df` to inspect the assets/files for this key.\n                 ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/xarray/conventions.py:440\u001b[0m, in \u001b[0;36mdecode_cf_variables\u001b[0;34m()\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 440\u001b[0m     new_vars[k] \u001b[38;5;241m=\u001b[39m decode_cf_variable(\n\u001b[1;32m    441\u001b[0m         k,\n\u001b[1;32m    442\u001b[0m         v,\n\u001b[1;32m    443\u001b[0m         concat_characters\u001b[38;5;241m=\u001b[39mconcat_characters,\n\u001b[1;32m    444\u001b[0m         mask_and_scale\u001b[38;5;241m=\u001b[39mmask_and_scale,\n\u001b[1;32m    445\u001b[0m         decode_times\u001b[38;5;241m=\u001b[39mdecode_times,\n\u001b[1;32m    446\u001b[0m         stack_char_dim\u001b[38;5;241m=\u001b[39mstack_char_dim,\n\u001b[1;32m    447\u001b[0m         use_cftime\u001b[38;5;241m=\u001b[39muse_cftime,\n\u001b[1;32m    448\u001b[0m         decode_timedelta\u001b[38;5;241m=\u001b[39mdecode_timedelta,\n\u001b[1;32m    449\u001b[0m     )\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/xarray/conventions.py:291\u001b[0m, in \u001b[0;36mdecode_cf_variable\u001b[0;34m()\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decode_times:\n\u001b[0;32m--> 291\u001b[0m     var \u001b[38;5;241m=\u001b[39m times\u001b[38;5;241m.\u001b[39mCFDatetimeCoder(use_cftime\u001b[38;5;241m=\u001b[39muse_cftime)\u001b[38;5;241m.\u001b[39mdecode(var, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decode_endianness \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m var\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39misnative:\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/xarray/coding/times.py:987\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m()\u001b[0m\n\u001b[1;32m    986\u001b[0m calendar \u001b[38;5;241m=\u001b[39m pop_to(attrs, encoding, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalendar\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 987\u001b[0m dtype \u001b[38;5;241m=\u001b[39m _decode_cf_datetime_dtype(data, units, calendar, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_cftime)\n\u001b[1;32m    988\u001b[0m transform \u001b[38;5;241m=\u001b[39m partial(\n\u001b[1;32m    989\u001b[0m     decode_cf_datetime,\n\u001b[1;32m    990\u001b[0m     units\u001b[38;5;241m=\u001b[39munits,\n\u001b[1;32m    991\u001b[0m     calendar\u001b[38;5;241m=\u001b[39mcalendar,\n\u001b[1;32m    992\u001b[0m     use_cftime\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_cftime,\n\u001b[1;32m    993\u001b[0m )\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/xarray/coding/times.py:212\u001b[0m, in \u001b[0;36m_decode_cf_datetime_dtype\u001b[0;34m()\u001b[0m\n\u001b[1;32m    210\u001b[0m values \u001b[38;5;241m=\u001b[39m indexing\u001b[38;5;241m.\u001b[39mImplicitToExplicitIndexingAdapter(indexing\u001b[38;5;241m.\u001b[39mas_indexable(data))\n\u001b[1;32m    211\u001b[0m example_value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[0;32m--> 212\u001b[0m     [first_n_items(values, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m [\u001b[38;5;241m0\u001b[39m], last_item(values) \u001b[38;5;129;01mor\u001b[39;00m [\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m    213\u001b[0m )\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/xarray/core/formatting.py:97\u001b[0m, in \u001b[0;36mfirst_n_items\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m     array \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39m_data\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mravel(to_duck_array(array))[:n_desired]\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/xarray/namedarray/pycompat.py:138\u001b[0m, in \u001b[0;36mto_duck_array\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(data)\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/xarray/core/indexing.py:573\u001b[0m, in \u001b[0;36m__array__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: np\u001b[38;5;241m.\u001b[39mtyping\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m--> 573\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_duck_array(), dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/xarray/core/indexing.py:576\u001b[0m, in \u001b[0;36mget_duck_array\u001b[0;34m()\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 576\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mget_duck_array()\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/xarray/core/indexing.py:650\u001b[0m, in \u001b[0;36mget_duck_array\u001b[0;34m()\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;66;03m# If the array is not an ExplicitlyIndexedNDArrayMixin,\u001b[39;00m\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;66;03m# it may wrap a BackendArray so use its __getitem__\u001b[39;00m\n\u001b[0;32m--> 650\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey]\n\u001b[1;32m    652\u001b[0m \u001b[38;5;66;03m# self.array[self.key] is now a numpy array when\u001b[39;00m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;66;03m# self.array is a BackendArray subclass\u001b[39;00m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;66;03m# and self.key is BasicIndexer((slice(None, None, None),))\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;66;03m# so we need the explicit check for ExplicitlyIndexed\u001b[39;00m\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/xarray/backends/zarr.py:104\u001b[0m, in \u001b[0;36m__getitem__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m     method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_oindex\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m indexing\u001b[38;5;241m.\u001b[39mexplicit_indexing_adapter(\n\u001b[1;32m    105\u001b[0m     key, array\u001b[38;5;241m.\u001b[39mshape, indexing\u001b[38;5;241m.\u001b[39mIndexingSupport\u001b[38;5;241m.\u001b[39mVECTORIZED, method\n\u001b[1;32m    106\u001b[0m )\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/xarray/core/indexing.py:1014\u001b[0m, in \u001b[0;36mexplicit_indexing_adapter\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1013\u001b[0m raw_key, numpy_indices \u001b[38;5;241m=\u001b[39m decompose_indexer(key, shape, indexing_support)\n\u001b[0;32m-> 1014\u001b[0m result \u001b[38;5;241m=\u001b[39m raw_indexing_method(raw_key\u001b[38;5;241m.\u001b[39mtuple)\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numpy_indices\u001b[38;5;241m.\u001b[39mtuple:\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;66;03m# index the loaded np.ndarray\u001b[39;00m\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/xarray/backends/zarr.py:94\u001b[0m, in \u001b[0;36m_getitem\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getitem\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_array[key]\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/zarr/core.py:798\u001b[0m, in \u001b[0;36m__getitem__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_pure_orthogonal_indexing(pure_selection, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim):\n\u001b[0;32m--> 798\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_orthogonal_selection(pure_selection, fields\u001b[38;5;241m=\u001b[39mfields)\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/zarr/core.py:1080\u001b[0m, in \u001b[0;36mget_orthogonal_selection\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1078\u001b[0m indexer \u001b[38;5;241m=\u001b[39m OrthogonalIndexer(selection, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1080\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_selection(indexer\u001b[38;5;241m=\u001b[39mindexer, out\u001b[38;5;241m=\u001b[39mout, fields\u001b[38;5;241m=\u001b[39mfields)\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/zarr/core.py:1343\u001b[0m, in \u001b[0;36m_get_selection\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1342\u001b[0m     lchunk_coords, lchunk_selection, lout_selection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mindexer)\n\u001b[0;32m-> 1343\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chunk_getitems(\n\u001b[1;32m   1344\u001b[0m         lchunk_coords,\n\u001b[1;32m   1345\u001b[0m         lchunk_selection,\n\u001b[1;32m   1346\u001b[0m         out,\n\u001b[1;32m   1347\u001b[0m         lout_selection,\n\u001b[1;32m   1348\u001b[0m         drop_axes\u001b[38;5;241m=\u001b[39mindexer\u001b[38;5;241m.\u001b[39mdrop_axes,\n\u001b[1;32m   1349\u001b[0m         fields\u001b[38;5;241m=\u001b[39mfields,\n\u001b[1;32m   1350\u001b[0m     )\n\u001b[1;32m   1351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mshape:\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/zarr/core.py:2183\u001b[0m, in \u001b[0;36m_chunk_getitems\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ckey \u001b[38;5;129;01min\u001b[39;00m cdatas:\n\u001b[0;32m-> 2183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_chunk(\n\u001b[1;32m   2184\u001b[0m         out,\n\u001b[1;32m   2185\u001b[0m         cdatas[ckey],\n\u001b[1;32m   2186\u001b[0m         chunk_select,\n\u001b[1;32m   2187\u001b[0m         drop_axes,\n\u001b[1;32m   2188\u001b[0m         out_is_ndarray,\n\u001b[1;32m   2189\u001b[0m         fields,\n\u001b[1;32m   2190\u001b[0m         out_select,\n\u001b[1;32m   2191\u001b[0m         partial_read_decode\u001b[38;5;241m=\u001b[39mpartial_read_decode,\n\u001b[1;32m   2192\u001b[0m     )\n\u001b[1;32m   2193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2194\u001b[0m     \u001b[38;5;66;03m# check exception type\u001b[39;00m\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/zarr/core.py:2096\u001b[0m, in \u001b[0;36m_process_chunk\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2095\u001b[0m     cdata \u001b[38;5;241m=\u001b[39m cdata\u001b[38;5;241m.\u001b[39mread_full()\n\u001b[0;32m-> 2096\u001b[0m chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode_chunk(cdata)\n\u001b[1;32m   2098\u001b[0m \u001b[38;5;66;03m# select data from chunk\u001b[39;00m\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/zarr/core.py:2352\u001b[0m, in \u001b[0;36m_decode_chunk\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2352\u001b[0m         chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compressor\u001b[38;5;241m.\u001b[39mdecode(cdata)\n\u001b[1;32m   2353\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32mnumcodecs/blosc.pyx:564\u001b[0m, in \u001b[0;36mnumcodecs.blosc.Blosc.decode\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mnumcodecs/blosc.pyx:394\u001b[0m, in \u001b[0;36mnumcodecs.blosc.decompress\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: error during blosc decompression: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/intake_esm/source.py:244\u001b[0m, in \u001b[0;36mESMDataSource._open_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m datasets \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    224\u001b[0m     _open_dataset(\n\u001b[1;32m    225\u001b[0m         record[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath_column_name],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, record \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39miterrows()\n\u001b[1;32m    242\u001b[0m ]\n\u001b[0;32m--> 244\u001b[0m datasets \u001b[38;5;241m=\u001b[39m \u001b[43mdask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(datasets) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/dask/base.py:662\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 662\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/intake_esm/source.py:77\u001b[0m, in \u001b[0;36m_open_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 77\u001b[0m     ds \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_dataset(url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mxarray_open_kwargs)\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m preprocess \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/xarray/backends/api.py:571\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m    570\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 571\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mopen_dataset(\n\u001b[1;32m    572\u001b[0m     filename_or_obj,\n\u001b[1;32m    573\u001b[0m     drop_variables\u001b[38;5;241m=\u001b[39mdrop_variables,\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecoders,\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    576\u001b[0m )\n\u001b[1;32m    577\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[1;32m    578\u001b[0m     backend_ds,\n\u001b[1;32m    579\u001b[0m     filename_or_obj,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    590\u001b[0m )\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/xarray/backends/zarr.py:1182\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m close_on_error(store):\n\u001b[0;32m-> 1182\u001b[0m     ds \u001b[38;5;241m=\u001b[39m store_entrypoint\u001b[38;5;241m.\u001b[39mopen_dataset(\n\u001b[1;32m   1183\u001b[0m         store,\n\u001b[1;32m   1184\u001b[0m         mask_and_scale\u001b[38;5;241m=\u001b[39mmask_and_scale,\n\u001b[1;32m   1185\u001b[0m         decode_times\u001b[38;5;241m=\u001b[39mdecode_times,\n\u001b[1;32m   1186\u001b[0m         concat_characters\u001b[38;5;241m=\u001b[39mconcat_characters,\n\u001b[1;32m   1187\u001b[0m         decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m   1188\u001b[0m         drop_variables\u001b[38;5;241m=\u001b[39mdrop_variables,\n\u001b[1;32m   1189\u001b[0m         use_cftime\u001b[38;5;241m=\u001b[39muse_cftime,\n\u001b[1;32m   1190\u001b[0m         decode_timedelta\u001b[38;5;241m=\u001b[39mdecode_timedelta,\n\u001b[1;32m   1191\u001b[0m     )\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/xarray/backends/store.py:46\u001b[0m, in \u001b[0;36mopen_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m encoding \u001b[38;5;241m=\u001b[39m filename_or_obj\u001b[38;5;241m.\u001b[39mget_encoding()\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28mvars\u001b[39m, attrs, coord_names \u001b[38;5;241m=\u001b[39m conventions\u001b[38;5;241m.\u001b[39mdecode_cf_variables(\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mvars\u001b[39m,\n\u001b[1;32m     48\u001b[0m     attrs,\n\u001b[1;32m     49\u001b[0m     mask_and_scale\u001b[38;5;241m=\u001b[39mmask_and_scale,\n\u001b[1;32m     50\u001b[0m     decode_times\u001b[38;5;241m=\u001b[39mdecode_times,\n\u001b[1;32m     51\u001b[0m     concat_characters\u001b[38;5;241m=\u001b[39mconcat_characters,\n\u001b[1;32m     52\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[1;32m     53\u001b[0m     drop_variables\u001b[38;5;241m=\u001b[39mdrop_variables,\n\u001b[1;32m     54\u001b[0m     use_cftime\u001b[38;5;241m=\u001b[39muse_cftime,\n\u001b[1;32m     55\u001b[0m     decode_timedelta\u001b[38;5;241m=\u001b[39mdecode_timedelta,\n\u001b[1;32m     56\u001b[0m )\n\u001b[1;32m     58\u001b[0m ds \u001b[38;5;241m=\u001b[39m Dataset(\u001b[38;5;28mvars\u001b[39m, attrs\u001b[38;5;241m=\u001b[39mattrs)\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/xarray/conventions.py:451\u001b[0m, in \u001b[0;36mdecode_cf_variables\u001b[0;34m()\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to decode variable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decode_coords \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoordinates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to decode variable 'time_bnds': error during blosc decompression: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mESMDataSourceError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:1\u001b[0m\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/pydantic/validate_call_decorator.py:60\u001b[0m, in \u001b[0;36mvalidate_call.<locals>.validate.<locals>.wrapper_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(function)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper_function\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalidate_call_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/pydantic/_internal/_validate_call.py:96\u001b[0m, in \u001b[0;36mValidateCallWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 96\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydantic_core\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mArgsKwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__return_pydantic_validator__:\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__return_pydantic_validator__(res)\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/intake_esm/core.py:686\u001b[0m, in \u001b[0;36mesm_datastore.to_dataset_dict\u001b[0;34m(self, xarray_open_kwargs, xarray_combine_by_coords_kwargs, preprocess, storage_options, progressbar, aggregate, skip_on_error, **kwargs)\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    685\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_on_error:\n\u001b[0;32m--> 686\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatasets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_derived_variables(datasets, skip_on_error)\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatasets\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/intake_esm/core.py:682\u001b[0m, in \u001b[0;36mesm_datastore.to_dataset_dict\u001b[0;34m(self, xarray_open_kwargs, xarray_combine_by_coords_kwargs, preprocess, storage_options, progressbar, aggregate, skip_on_error, **kwargs)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m gen:\n\u001b[1;32m    681\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 682\u001b[0m         key, ds \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    683\u001b[0m         datasets[key] \u001b[38;5;241m=\u001b[39m ds\n\u001b[1;32m    684\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/intake_esm/core.py:833\u001b[0m, in \u001b[0;36m_load_source\u001b[0;34m(key, source)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_source\u001b[39m(key, source):\n\u001b[0;32m--> 833\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m key, \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/intake_esm/source.py:272\u001b[0m, in \u001b[0;36mESMDataSource.to_dask\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_dask\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    271\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return xarray object (which will have chunks)\"\"\"\u001b[39;00m\n\u001b[0;32m--> 272\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ds\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/intake/source/base.py:283\u001b[0m, in \u001b[0;36mDataSourceBase._load_metadata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"load metadata only if needed\"\"\"\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 283\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/intake_esm/source.py:208\u001b[0m, in \u001b[0;36mESMDataSource._get_schema\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_schema\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Schema:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m         metadata: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, typing\u001b[38;5;241m.\u001b[39mAny] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdims\u001b[39m\u001b[38;5;124m'\u001b[39m: {}, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_vars\u001b[39m\u001b[38;5;124m'\u001b[39m: {}, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoords\u001b[39m\u001b[38;5;124m'\u001b[39m: ()}\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema \u001b[38;5;241m=\u001b[39m Schema(\n\u001b[1;32m    211\u001b[0m             datashape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    212\u001b[0m             dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m             extra_metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[1;32m    216\u001b[0m         )\n",
      "File \u001b[0;32m/glade/work/harshah/conda-envs/arco_experiments/lib/python3.12/site-packages/intake_esm/source.py:264\u001b[0m, in \u001b[0;36mESMDataSource._open_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ds\u001b[38;5;241m.\u001b[39mattrs[OPTIONS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset_key\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ESMDataSourceError(\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mFailed to load dataset with key=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;124m         You can use `cat[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m].df` to inspect the assets/files for this key.\u001b[39m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;124m         \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    268\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mESMDataSourceError\u001b[0m: Failed to load dataset with key='atm.historical.daily.smbb'\n                 You can use `cat['atm.historical.daily.smbb'].df` to inspect the assets/files for this key.\n                 "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dsets_cesm = cesm_temp.to_dataset_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63ba6df1-c054-4893-a87f-9f87a6b412d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dsets_cesm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m historical_smbb  \u001b[38;5;241m=\u001b[39m \u001b[43mdsets_cesm\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124matm.historical.daily.smbb\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      2\u001b[0m future_smbb      \u001b[38;5;241m=\u001b[39m dsets_cesm[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124matm.ssp370.daily.smbb\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m historical_cmip6 \u001b[38;5;241m=\u001b[39m dsets_cesm[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124matm.historical.daily.cmip6\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dsets_cesm' is not defined"
     ]
    }
   ],
   "source": [
    "historical_smbb  = dsets_cesm['atm.historical.daily.smbb']\n",
    "future_smbb      = dsets_cesm['atm.ssp370.daily.smbb']\n",
    "\n",
    "historical_cmip6 = dsets_cesm['atm.historical.daily.cmip6']\n",
    "future_cmip6     = dsets_cesm['atm.ssp370.daily.cmip6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1944d35a-cf70-47b0-94a2-2861cb6c8a9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "historical_smbb_init = historical_smbb.TREFHTMX.sel(time=slice(init_year0, init_year1))\n",
    "historical_smbb_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f36a8b3-fdb6-4d16-8fa7-1e42da3eebc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Plot sample data\n",
    "historical_smbb.TREFHTMX.isel(member_id=0,time=0).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c622674-7884-4312-a039-c813f9293783",
   "metadata": {},
   "source": [
    "## Data Access Speed tests\n",
    "- We will now test how long it takes to access data (via OSDF) for various sizes using one of the above arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8706542e-54b5-4c8f-b74b-691d4ff7c996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 0 : Single data point, Mem: 4 bytes. Takes 1 min 30s when .compute() is called on this data array (which loads data into memory)\n",
    "historical_smbb_init0 = historical_smbb_init.isel(lat=0,lon=0,time=0,member_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c1440b-9f47-4ef5-a187-143544c09aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test 1: Whole globe +all member_ids for 1 time step, Mem: 10.55 MiB ~ 10.55 MB\n",
    "historical_smbb_init1 = historical_smbb_init.isel(time=0)\n",
    "historical_smbb_init1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888409b9-2c40-4551-85aa-6538a7f9e232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try using a specific cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9149f2-3b73-4441-9f9e-8cce45ed324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdsc_cache='https://sdsc-cache.nationalresearchplatform.org:8443/aws-opendata/us-west-2/ncar-cesm2-lens/atm/monthly/cesm2LE-historical-smbb-TREFHTMX.zarr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6aea28-8474-418c-be83-93ddd243e236",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_1 = xr.open_zarr(sdsc_cache).TREFHTMX.isel(time=0)\n",
    "test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b14601-6015-4e73-8bbd-9021fddccca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# test_1.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4680869f-5122-4c5f-9f1f-585aa2d7c821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, try to access the same array without specifying the cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1c9655-bf7c-439f-9b2b-017f29d0bd12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "historical_smbb_init1.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fc94d3-e5ec-4221-8d62-5948cc1a3db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the same object via the NCAR origin\n",
    "ncar_glade_test = xr.open_zarr('osdf:///ncar/rda-transfer/chifan_AWS/ncar-cesm2-lens/atm/monthly/cesm2LE-historical-smbb-TREFHTMX.zarr').TREFHTMX.isel(time=0)\n",
    "ncar_glade_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d57a9c-2371-4de5-88bc-02ecfe499b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# ncar_glade_test.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43bbedd-909b-4bba-bbe9-0043b6cd5fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# merge_ds_smbb = xr.concat([historical_smbb, future_smbb], dim='time')\n",
    "# merge_ds_smbb = merge_ds_smbb.dropna(dim='member_id')\n",
    "\n",
    "# merge_ds_cmip6= xr.concat([historical_cmip6, future_cmip6], dim='time')\n",
    "# merge_ds_cmip6 = merge_ds_cmip6.dropna(dim='member_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343c5b75-1706-455c-99a1-984c666f762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_smbb      = merge_ds_smbb.TREFHTMX\n",
    "# t_cmip6     = merge_ds_cmip6.TREFHTMX\n",
    "# t_init_cmip6 = t_cmip6.sel(time=slice(init_year0, init_year1))\n",
    "# t_init_smbb  = t_smbb.sel(time=slice(init_year0, init_year1))\n",
    "# t_init       = xr.concat([t_init_cmip6,t_init_smbb],dim='member_id')\n",
    "# t_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc673ff-036a-49d6-97c6-b48835a95906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_init_day = to_daily(t_init)\n",
    "# #t_init_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3d5ac5-957b-4fa8-81b9-f6eda0601a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t_fut_cmip6 = t_cmip6.sel(time=slice(final_year0, final_year1))\n",
    "# t_fut_smbb  = t_smbb.sel(time=slice(final_year0, final_year1))\n",
    "# t_fut       = xr.concat([t_fut_cmip6,t_fut_smbb],dim='member_id')\n",
    "# t_fut_day   = to_daily(t_fut)\n",
    "# t_fut_day"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec85a550-5e99-4a66-98ab-25b984cd481a",
   "metadata": {},
   "source": [
    "### Save means and standard deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dc4f5c-940c-4c86-82b4-43b2cd72f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_means   = t_init_day.mean({'year','member_id'})\n",
    "# init_stdevs  = t_init_day.std({'year','member_id'})\n",
    "# final_means  = t_fut_day.mean({'year','member_id'})\n",
    "# final_stdevs = t_fut_day.std({'year','member_id'})\n",
    "#\n",
    "# init_ensemble_means  = t_init_day.mean({'member_id'})\n",
    "# final_ensemble_means = t_fut_day.mean({'member_id'})\n",
    "# init_ensemble_means  = init_ensemble_means.chunk({'lat':192,'lon':288,'year':2,'day':365})\n",
    "# final_ensemble_means = final_ensemble_means.chunk({'lat':192,'lon':288,'year':2,'day':365})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccc8ce3-a11e-4cfb-b563-2be618d4cfd2",
   "metadata": {},
   "source": [
    "- Save the overall means, standard devaitions and the ensemble means\n",
    "- We will regrid the 'final/EOC' ensemble means onto the ERA5 grid.\n",
    "- We will then compare it with the bias-corrected future predictions obtained from ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410f94d7-2754-4e5b-82b9-398288dd4842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# init_means.to_dataset().to_zarr(mean_path + 'cesm2_'+ init_year0 + '_' + init_year1+ '_means.zarr',mode='w')\n",
    "# init_stdevs.to_dataset().to_zarr(stdev_path + 'cesm2_'+ init_year0 + '_' + init_year1+ '_stdevs.zarr',mode='w') \n",
    "# final_means.to_dataset().to_zarr(mean_path + 'cesm2_'+ final_year0 + '_' + final_year1+ '_means.zarr',mode='w')\n",
    "# final_stdevs.to_dataset().to_zarr(stdev_path + 'cesm2_'+ final_year0 + '_' + final_year1+ '_stdevs.zarr',mode='w') \n",
    "# init_ensemble_means.to_dataset().to_zarr(mean_path + 'cesm2_'+ init_year0 + '_' + init_year1 \\\n",
    "#                                          + '_ensemble_means.zarr',mode='w')\n",
    "# final_ensemble_means.to_dataset().to_zarr(mean_path + 'cesm2_'+ final_year0 + '_' + final_year1 \\\n",
    "#                                           + '_ensemble_means.zarr',mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e248333-8828-46db-a491-5697a103b485",
   "metadata": {},
   "source": [
    "## Access ERA5 data and regrid CESM2 LENS data on the finer, ERA5 grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3142db-6ed0-4331-b994-3b78db3d7d29",
   "metadata": {},
   "source": [
    "- In this section, we will load pre-processed ERA5 data from the NCAR origin\n",
    "- We will not use an intake catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbb0965-b253-4be3-ae6f-05e38fe431cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create OSDF file path for the ERA5 zarr store\n",
    "namespace        = 'ncar/'   #NCAR's Research Data Archive\n",
    "# osdf_director    = 'https://osdf-director.osg-htc.org/'\n",
    "osdf_director    = 'osdf:///'\n",
    "era5_zarr_path   = namespace + 'rda/harshah/era5_tas/zarr/e5_tas2m_daily_1940_2023.zarr'\n",
    "#\n",
    "# pelfs = PelicanFileSystem(osdf_director)\n",
    "pelfs = OSDFFileSystem()\n",
    "#\n",
    "pel_zarr         = PelicanMap(era5_zarr_path, pelfs)\n",
    "print(era5_zarr_path)\n",
    "osdf_protocol_era5path = osdf_director + era5_zarr_path\n",
    "print(osdf_protocol_era5path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1153f99-700e-49a8-ac1e-79c5f28fcfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tas_obs_daily = xr.open_zarr(osdf_protocol_era5path).VAR_2T\n",
    "tas_obs_init = tas_obs_daily.sel(time=slice(init_year0, init_year1))\n",
    "tas_obs_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875670c1-53e6-4ce0-8813-c302b9b63c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tas_obs_init.isel(time=0).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3b6339-fe60-49a7-8ed5-3fe268cd80d8",
   "metadata": {},
   "source": [
    "### Perform Bias Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0e4932-7f2f-44a8-a934-39853a1667ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_means_ds = xr.open_zarr(mean_path + 'cesm2_'+ init_year0 + '_' + init_year1+ '_means.zarr')\n",
    "init_means    = init_means_ds.TREFHTMX\n",
    "init_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686d452c-c1ea-4b67-8f0a-0301ac92763a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_means  = xr.open_zarr(mean_path  + 'cesm2_'+ final_year0 + '_' + final_year1+ '_means.zarr').TREFHTMX\n",
    "init_stdevs  = xr.open_zarr(stdev_path + 'cesm2_'+ init_year0 + '_' + init_year1+ '_stdevs.zarr').TREFHTMX\n",
    "final_stdevs = xr.open_zarr(stdev_path + 'cesm2_'+ final_year0 + '_' + final_year1+ '_stdevs.zarr').TREFHTMX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73737f3e-ee1d-4bf8-88cc-a4773158b2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create output grid\n",
    "ds_out = xr.Dataset(\n",
    "    coords={\n",
    "        'latitude': tas_obs_init.coords['latitude'],\n",
    "        'longitude': tas_obs_init.coords['longitude']\n",
    "    }\n",
    ")\n",
    "ds_out = ds_out.rename({'latitude':'lat','longitude':'lon'})\n",
    "ds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee7e7fe-fca4-4bb6-9846-0060e1744b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_obs_initial    = to_daily(tas_obs_init)\n",
    "tas_obs_initial    = tas_obs_initial.rename({'latitude':'lat','longitude':'lon'})\n",
    "tas_obs_initial    = tas_obs_initial.chunk({'lat':139,'lon':544,'year':3,'day':90})\n",
    "tas_obs_initial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e76d693-5ec0-4aa6-8c7c-a9dbb935a92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# tas_obs_initial.to_dataset().to_zarr(zarr_path + \"e5_tas2m_initial_1991_2020.zarr\",mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd94a5f-d6cb-4f24-a71b-d7940e66bdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_obs_initial = xr.open_zarr(zarr_path + \"e5_tas2m_initial_1991_2020.zarr\").VAR_2T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5667476c-d546-4721-a221-c3febf878ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "regridder = xe.Regridder(init_means_ds, ds_out, \"bilinear\")\n",
    "regridder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca98aefa-61b8-4e30-b34c-a3c716ef2334",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_means_regrid = regridder(init_means, keep_attrs=True)\n",
    "init_means_regrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584bdf59-6f0f-403d-b8fa-9cc08c4d925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Regrid other variables\n",
    "init_stdevs_regrid  = regridder(init_stdevs, keep_attrs=True)\n",
    "final_means_regrid  = regridder(final_means, keep_attrs=True)\n",
    "final_stdevs_regrid = regridder(final_stdevs, keep_attrs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665b1cd5-0d89-48ae-b5af-9091997d43c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #Save regridded data\n",
    "# init_means_regrid.to_dataset().to_zarr(mean_path + 'cesm2_'+ init_year0 + '_' + init_year1+ '_means_regridded.zarr',mode='w')\n",
    "# init_stdevs_regrid.to_dataset().to_zarr(stdev_path + 'cesm2_'+ init_year0 + '_' + init_year1+ '_stdevs_regridded.zarr',mode='w') \n",
    "# final_means_regrid.to_dataset().to_zarr(mean_path + 'cesm2_'+ final_year0 + '_' + final_year1+ '_means_regridded.zarr',mode='w')\n",
    "# final_stdevs_regrid.to_dataset().to_zarr(stdev_path + 'cesm2_'+ final_year0 + '_' + final_year1+ '_stdevs_regridded.zarr',mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1d097d-32bd-4165-9e62-10c006513435",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Open regridded data\n",
    "init_means_regrid  = xr.open_zarr(mean_path + 'cesm2_'+ init_year0 + '_' + init_year1+ '_means_regridded.zarr').TREFHTMX\n",
    "init_stdevs_regrid = xr.open_zarr(stdev_path + 'cesm2_'+ init_year0 + '_' + init_year1+ '_stdevs_regridded.zarr').TREFHTMX\n",
    "final_means_regrid  = xr.open_zarr(mean_path + 'cesm2_'+ final_year0 + '_' + final_year1+ '_means_regridded.zarr').TREFHTMX\n",
    "final_stdevs_regrid = xr.open_zarr(stdev_path + 'cesm2_'+ final_year0 + '_' + final_year1+ '_stdevs_regridded.zarr').TREFHTMX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca7a7ca-30b1-4048-acf4-161d9cdc91ea",
   "metadata": {},
   "source": [
    "## Now, perform bias correction by only adjusting the first moment, i.e, mean and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e94183-bcf4-4803-84c0-aad9c2cac2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_bc = tas_obs_initial  + (final_means_regrid - init_means_regrid)\n",
    "tas_bc = tas_bc.chunk({'lat':139,'lon':544,'year':3,'day':90})\n",
    "tas_bc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad63b9e2-6e4b-465d-bc60-684429a46e0c",
   "metadata": {},
   "source": [
    "### Plot bias corrected temperature and CESM model's predictions for the End of the 21st century (2100)\n",
    "- Since tas_bc are predictions for the years 2070-2100, we need to change the year coordinated\n",
    "- We will then save the bias-corrected surface air temperatures (tas) to a zarr store.\n",
    "- Finally, we will read from this zarr store and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77ede3c-1674-4d32-b34b-5474de11411f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the year coordinate\n",
    "tas_bc['year'] = tas_bc['year'] + 80\n",
    "tas_bc         = tas_bc.rename('bias_corrected_tas')\n",
    "tas_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed64597-bd12-4ba8-b53c-d91987377c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# tas_bc.to_dataset().to_zarr(zarr_path + 'bias_corrected_tas_1991_2020.zarr',mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c987333-de8b-45f6-b690-7c7f3c42ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "tas_bc = xr.open_zarr(zarr_path + 'bias_corrected_tas_1991_2020.zarr').bias_corrected_tas\n",
    "tas_bc = tas_bc.sortby('lat',ascending=True)\n",
    "tas_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e697119b-d081-4581-9452-71833ac59fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ensemble_means = xr.open_zarr(mean_path + 'cesm2_'+ final_year0 + '_' + final_year1 + '_ensemble_means.zarr').TREFHTMX\n",
    "final_ensemble_means = final_ensemble_means.sortby('lat',ascending=True)\n",
    "final_ensemble_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93349d05-ec38-48d9-95a5-55715c435aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tas_bc.sel(year = 2100, day = 211).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa03e7c9-537d-4393-9d8b-218d6ba8e73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ensemble_means.sel(year = 2100, day = 211).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abed4842-ead0-4a97-b04e-f3069f4bf1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Plot the first array\n",
    "tas_bc.sel(year = 2100, day = 211).plot(ax = axs[0],cmap='RdBu_r',add_colorbar=False)\n",
    "axs[0].set_title('Bias-corrected projections')\n",
    "#axs[0].coastlines(color=\"black\")\n",
    "\n",
    "# Plot the second array\n",
    "final_ensemble_means.sel(year = 2100, day = 211).plot(ax = axs[1],cmap='RdBu_r')\n",
    "axs[1].set_title('EOC model ensemble means')\n",
    "\n",
    "# Display the plots\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:arco_experiments]",
   "language": "python",
   "name": "conda-env-arco_experiments-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
